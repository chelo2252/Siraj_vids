{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-360K.html\n",
    "\n",
    "https://github.com/lyst/lightfm/issues/174\n",
    "\n",
    "https://github.com/lyst/lightfm/tree/master/examples/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Miniconda3\\envs\\keras_gpu\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from lightfm import LightFM\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "ndata_name = 'normalized_data'\n",
    "ndata =ndata_name+'.npz'\n",
    "if not os.path.isfile(ndata):\n",
    "    # uncompressed dataset\n",
    "    fname = 'D:\\Sistemas\\datasets\\lastfm-dataset-360K.tar.gz'\n",
    "    if (fname.endswith(\"tar.gz\")):\n",
    "        tar = tarfile.open(fname, \"r:gz\")\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "    elif (fname.endswith(\"tar\")):\n",
    "        tar = tarfile.open(fname, \"r:\")\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        \n",
    "    # read uncompressed data\n",
    "\n",
    "    headers = [\"user_id\", \"artist_id\", \"artist_name\", \"plays\"]\n",
    "\n",
    "    data = pd.read_csv(\"lastfm-dataset-360K\\\\usersha1-artmbid-artname-plays.tsv\", sep=\"\\t\", header=None, names=headers)\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # normalize data, based on the amount of listenings of each user\n",
    "    # if the user has listened more times that artist is understood that it likes it more, \n",
    "    # so it gets a higher score\n",
    "\n",
    "    # position 0: user index\n",
    "    # position 1: artist index\n",
    "    users = set(data[np.arange(data.shape[0]),0])\n",
    "    user2ui = dict(zip(users,range(len(users))))\n",
    "    items = set(data[np.arange(data.shape[0]),1])\n",
    "    items2ui = dict(zip(items,range(len(items))))\n",
    "\n",
    "    user2Views = dict()\n",
    "    for user in users:\n",
    "        user2Views[user] = []\n",
    "    for value in data:\n",
    "        user2Views[value[0]].append(value)\n",
    "    for user in users:\n",
    "        user2Views[user] = np.array(user2Views[user])\n",
    "    for key, value in user2Views.items():\n",
    "        filas_user = np.arange(len(value))\n",
    "        actual = value[filas_user,3]\n",
    "\n",
    "        value[filas_user,3] = actual/max(actual)*5\n",
    "\n",
    "    data = []\n",
    "    for key, value in user2Views.items():\n",
    "        data.extend(value)\n",
    "\n",
    "    data = np.array(data) \n",
    "\n",
    "    # save data\n",
    "    np.savez(ndata_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if enough memory continue, if not restart kernel\n",
    "npzfile = np.load(ndata)\n",
    "data = npzfile['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    return num != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all rows with a nan id\n",
    "\n",
    "toDelete = []\n",
    "for index, row in enumerate(data):\n",
    "    if isNaN(row[0]) or isNaN(row[1]) or isNaN(row[2]):\n",
    "        toDelete.append(index)\n",
    "        \n",
    "data = np.delete(data, toDelete, 0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = set()\n",
    "items = set()\n",
    "\n",
    "# cast to string due to object comparison (it's faster)\n",
    "for idx,row in enumerate(data):\n",
    "    users.add(str(row[0]))\n",
    "    items.add(str(row[1]))\n",
    "\n",
    "user2ui = dict(zip(users,range(len(users))))\n",
    "items2ui = dict(zip(items,range(len(items))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.8*data.shape[0])\n",
    "n_test = int(0.2*data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[np.random.choice(n_train,n_train, replace=False)]\n",
    "test_data = data[np.random.choice(n_test,n_test, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(users)\n",
    "n_items = len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_interaction_matrix(rows, cols, data, user2ui, items2ui , min_plays):\n",
    "\n",
    "    mat = sp.lil_matrix((rows, cols), dtype=np.int32)\n",
    "\n",
    "    for uid, iid, _, plays in data:\n",
    "        mat[user2ui[uid], items2ui[iid]] = plays\n",
    "\n",
    "    return mat.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = _build_interaction_matrix(n_users, n_items, train_data, user2ui, items2ui, 3)\n",
    "test = _build_interaction_matrix(n_users, n_items, test_data, user2ui, items2ui, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_features = sp.identity(n_items, format=\"csr\", dtype=np.float32)\n",
    "id_feature_labels = np.empty(n_items, dtype=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid,iid,imeta,_ in data:\n",
    "    id_feature_labels[items2ui[iid]] = imeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = {\n",
    "    \"train\": train,\n",
    "    \"test\": test,\n",
    "    \"item_features\": id_features,\n",
    "    \"item_feature_labels\": id_feature_labels,\n",
    "    \"item_labels\": id_feature_labels,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<358858x160111 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 6261451 stored elements in COOrdinate format>\n",
      "<358858x160111 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 1564393 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "#print training and testing data\n",
    "print(repr(xdata['train']))\n",
    "print(repr(xdata['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(loss,data,epochs=30,num_threads=4):\n",
    "    #create model\n",
    "    model = LightFM(loss=loss)\n",
    "    #train model\n",
    "    model.fit(data['train'], epochs=epochs, num_threads=num_threads)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "\n",
    "    #number of users and artist in training data\n",
    "    n_users, n_items = data['train'].shape\n",
    "\n",
    "    #generate recommendations for each user we input\n",
    "    for user_id in user_ids:\n",
    "        #artist they already like\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "\n",
    "        #artist our model predicts they will like\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        #rank them in order of most liked to least\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        #print out the results\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "\n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_model(model,fname):\n",
    "    with open(fname, 'wb') as fle:\n",
    "        pickle.dump(model, fle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHALLENGE part 2 of 3 - use 3 different loss functions (so 3 different models), compare results, print results for\n",
    "#the best one. - Available loss functions are warp, logistic, bpr, and warp-kos.\n",
    "\n",
    "warp_model = get_model(\"warp\",xdata,num_threads=8)\n",
    "save_model(warp_model,\"warp_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = get_model(\"logistic\",xdata,num_threads=8)\n",
    "save_model(logistic_model,\"logistic_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_model = get_model(\"bpr\",xdata,num_threads=8)\n",
    "save_model(bpr_model,\"bpr_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkos_model = get_model(\"warp-kos\",xdata,num_threads=8)\n",
    "save_model(wkos_model,\"wkos_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2000\n",
      "     Known positives:\n",
      "        barış akarsu\n",
      "        salvatore adamo\n",
      "        aleš brichta\n",
      "     Recommended:\n",
      "        enya\n",
      "        loreena mckennitt\n",
      "        clannad\n",
      "User 20000\n",
      "     Known positives:\n",
      "        nine inch nails\n",
      "        zемфира\n",
      "        massive attack\n",
      "     Recommended:\n",
      "        pink floyd\n",
      "        metallica\n",
      "        iron maiden\n",
      "User 30000\n",
      "     Known positives:\n",
      "        jason mraz\n",
      "        diana krall\n",
      "        red hot chili peppers\n",
      "     Recommended:\n",
      "        kanye west\n",
      "        jack johnson\n",
      "        the beatles\n",
      "User 40000\n",
      "     Known positives:\n",
      "        red hot chili peppers\n",
      "        system of a down\n",
      "        regina spektor\n",
      "     Recommended:\n",
      "        radiohead\n",
      "        the beatles\n",
      "        coldplay\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(warp_model, xdata, [2000,20000,30000,40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2000\n",
      "     Known positives:\n",
      "        barış akarsu\n",
      "        salvatore adamo\n",
      "        aleš brichta\n",
      "     Recommended:\n",
      "        radiohead\n",
      "        the beatles\n",
      "        coldplay\n",
      "User 20000\n",
      "     Known positives:\n",
      "        nine inch nails\n",
      "        zемфира\n",
      "        massive attack\n",
      "     Recommended:\n",
      "        radiohead\n",
      "        the beatles\n",
      "        coldplay\n",
      "User 30000\n",
      "     Known positives:\n",
      "        jason mraz\n",
      "        diana krall\n",
      "        red hot chili peppers\n",
      "     Recommended:\n",
      "        radiohead\n",
      "        the beatles\n",
      "        coldplay\n",
      "User 40000\n",
      "     Known positives:\n",
      "        red hot chili peppers\n",
      "        system of a down\n",
      "        regina spektor\n",
      "     Recommended:\n",
      "        radiohead\n",
      "        the beatles\n",
      "        coldplay\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(logistic_model, xdata, [2000,20000,30000,40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2000\n",
      "     Known positives:\n",
      "        barış akarsu\n",
      "        salvatore adamo\n",
      "        aleš brichta\n",
      "     Recommended:\n",
      "        bad boys blue\n",
      "        yanni\n",
      "        hevia\n",
      "User 20000\n",
      "     Known positives:\n",
      "        nine inch nails\n",
      "        zемфира\n",
      "        massive attack\n",
      "     Recommended:\n",
      "        pink floyd\n",
      "        queen\n",
      "        u2\n",
      "User 30000\n",
      "     Known positives:\n",
      "        jason mraz\n",
      "        diana krall\n",
      "        red hot chili peppers\n",
      "     Recommended:\n",
      "        john mayer\n",
      "        jack johnson\n",
      "        jason mraz\n",
      "User 40000\n",
      "     Known positives:\n",
      "        red hot chili peppers\n",
      "        system of a down\n",
      "        regina spektor\n",
      "     Recommended:\n",
      "        radiohead\n",
      "        the beatles\n",
      "        bloc party\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(bpr_model, xdata, [2000,20000,30000,40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 2000\n",
      "     Known positives:\n",
      "        barış akarsu\n",
      "        salvatore adamo\n",
      "        aleš brichta\n",
      "     Recommended:\n",
      "        the beatles\n",
      "        simon & garfunkel\n",
      "        bob dylan\n",
      "User 20000\n",
      "     Known positives:\n",
      "        nine inch nails\n",
      "        zемфира\n",
      "        massive attack\n",
      "     Recommended:\n",
      "        deep purple\n",
      "        queen\n",
      "        genesis\n",
      "User 30000\n",
      "     Known positives:\n",
      "        jason mraz\n",
      "        diana krall\n",
      "        red hot chili peppers\n",
      "     Recommended:\n",
      "        kanye west\n",
      "        eminem\n",
      "        michael jackson\n",
      "User 40000\n",
      "     Known positives:\n",
      "        red hot chili peppers\n",
      "        system of a down\n",
      "        regina spektor\n",
      "     Recommended:\n",
      "        muse\n",
      "        placebo\n",
      "        franz ferdinand\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(wkos_model, xdata, [2000,20000,30000,40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras_gpu)",
   "language": "python",
   "name": "keras_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
